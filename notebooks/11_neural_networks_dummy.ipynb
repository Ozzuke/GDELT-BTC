{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:18.390613Z",
     "start_time": "2024-12-08T20:33:18.371426Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:20.941352Z",
     "start_time": "2024-12-08T20:33:18.415049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data = pd.read_parquet('../cache/encoded_99q_scaled.parquet')"
   ],
   "id": "f03b740df0f7c595",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.022825Z",
     "start_time": "2024-12-08T20:33:21.008881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GDELT(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        if hasattr(features, 'values'):\n",
    "            features = features.values\n",
    "        if hasattr(target, 'values'):\n",
    "            target = target.values\n",
    "           \n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]"
   ],
   "id": "293439ff67b6a91a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.090116Z",
     "start_time": "2024-12-08T20:33:21.073671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # simple neural network with 3 layers (linear)\n",
    "        self.network = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(input_dim, 128), # input layer to hidden layer 1 with 128 neurons\n",
    "            nn.BatchNorm1d(128), # batch normalization layer to normalize the output of the 1st layer before activation function is applied to it\n",
    "            nn.ReLU(), # activation function to introduce non-linearity to the model output from the 1st layer\n",
    "            nn.Dropout(0.3), # dropout layer to prevent overfitting by randomly setting 30% of the output from the 1st layer to 0\n",
    "        \n",
    "            # 2nd layer\n",
    "            nn.Linear(128, 64), # hidden layer 1 to hidden layer 2 with 64 neurons\n",
    "            nn.BatchNorm1d(64), # batch normalization layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.Dropout(0.3), # dropout layer\n",
    "        \n",
    "            # 3rd layer\n",
    "            nn.Linear(64, 32), # hidden layer 2 to hidden layer 3 with 32 neurons\n",
    "            nn.BatchNorm1d(32), # batch normalization layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.Dropout(0.3), # dropout layer\n",
    "        \n",
    "            # output layer\n",
    "            nn.Linear(32, 1) # hidden layer 3 to output layer with 1 neuron\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "id": "a79894d2e5735342",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.168725Z",
     "start_time": "2024-12-08T20:33:21.152916Z"
    }
   },
   "cell_type": "code",
   "source": "data.columns",
   "id": "514519bd36ec2724",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Actor1Country', 'Actor1GeoCountry', 'Actor1Type',\n",
       "       'Actor2Country', 'Actor2GeoCountry', 'Actor2Type', 'ActionCountry',\n",
       "       'EventType', 'GoldsteinScale', 'NumSources', 'NumArticles', 'AvgTone',\n",
       "       'Magnitude', 'Impact', 'Impact_bin', 'pct_change_15min',\n",
       "       'pct_change_30min', 'pct_change_24h', 'AbsChange'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.249140Z",
     "start_time": "2024-12-08T20:33:21.231907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prep_data(df, target='pct_change_30min'):\n",
    "    feature_cols = [\n",
    "        'Actor1Country', 'Actor1GeoCountry', 'Actor1Type',\n",
    "        'Actor2Country', 'Actor2GeoCountry', 'Actor2Type',\n",
    "        'ActionCountry', 'EventType', 'GoldsteinScale',\n",
    "        'NumSources', 'NumArticles', 'AvgTone',\n",
    "        'Magnitude', 'Impact'\n",
    "    ]\n",
    "        \n",
    "    x = df[feature_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    \n",
    "    return x_scaled, y, scaler"
   ],
   "id": "40984dcb08acc1bf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.336024Z",
     "start_time": "2024-12-08T20:33:21.308835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(x, y, batch_size=256, epochs=50, learning_rate=0.001, patience=10):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    train_idx, test_idx = list(tscv.split(x))[-1] # use the last split as test set\n",
    "    \n",
    "    x_train, y_train = x[train_idx], y[train_idx]\n",
    "    x_val, y_val = x[test_idx], y[test_idx]\n",
    "    \n",
    "    train_dataset = GDELT(x_train, y_train)\n",
    "    val_dataset = GDELT(x_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = PricePredictor(x.shape[1])\n",
    "    \n",
    "    criterion = nn.MSELoss() # loss function (mean squared error)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for features, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, target.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, target in val_loader:\n",
    "                output = model(features)\n",
    "                loss = criterion(output, target.reshape(-1, 1))\n",
    "                val_loss += loss.item()\n",
    "                predictions.extend(output.numpy().flatten())\n",
    "                actuals.extend(target.numpy().flatten())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, accuracy: {np.mean(np.sign(predictions) == np.sign(actuals))}')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(f'Early stopping at epoch {epoch+1} with val loss: {val_loss:.4f}')\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_model.state_dict())\n",
    "    return model"
   ],
   "id": "efb9f0b31df5409f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:21.440253Z",
     "start_time": "2024-12-08T20:33:21.394874Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "40c9b1e978879593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Timestamp  Actor1Country  Actor1GeoCountry  Actor1Type  \\\n",
       "Date                                                                 \n",
       "2019-01-01  -1.530752              9                13           9   \n",
       "2019-01-01  -1.530752              9                13           9   \n",
       "2019-01-01  -1.530752              9                13           9   \n",
       "2019-01-01  -1.530752              9                13           9   \n",
       "2019-01-01  -1.530752              9                13           9   \n",
       "\n",
       "            Actor2Country  Actor2GeoCountry  Actor2Type  ActionCountry  \\\n",
       "Date                                                                     \n",
       "2019-01-01             13                11           9             11   \n",
       "2019-01-01             13                11           9             11   \n",
       "2019-01-01             13                11           9             11   \n",
       "2019-01-01             13                11           9             11   \n",
       "2019-01-01             13                11           9             11   \n",
       "\n",
       "            EventType  GoldsteinScale  NumSources  NumArticles   AvgTone  \\\n",
       "Date                                                                       \n",
       "2019-01-01         10        0.605751    0.889228     2.004333  1.164239   \n",
       "2019-01-01         10        0.731167    0.367070     0.597142  0.468568   \n",
       "2019-01-01         10        0.563945    4.022178     1.300737  1.004049   \n",
       "2019-01-01         10       -0.523000    0.367070    -0.036094 -0.520616   \n",
       "2019-01-01         10        0.292209    1.933545    -0.247173  0.921836   \n",
       "\n",
       "            Magnitude    Impact         Impact_bin  pct_change_15min  \\\n",
       "Date                                                                   \n",
       "2019-01-01   0.375252  0.714246           Positive         -0.033061   \n",
       "2019-01-01  -0.716820  0.425568  Slightly Positive         -0.033061   \n",
       "2019-01-01   0.960180  0.848379           Positive         -0.033061   \n",
       "2019-01-01   0.334805 -0.355905  Slightly Negative         -0.033061   \n",
       "2019-01-01  -0.100779  0.329342  Slightly Positive         -0.033061   \n",
       "\n",
       "            pct_change_30min  pct_change_24h  AbsChange  \n",
       "Date                                                     \n",
       "2019-01-01         -0.226363       -2.433464  -0.199873  \n",
       "2019-01-01         -0.226363       -2.433464  -0.199873  \n",
       "2019-01-01         -0.226363       -2.433464  -0.199873  \n",
       "2019-01-01         -0.226363       -2.433464  -0.199873  \n",
       "2019-01-01         -0.226363       -2.433464  -0.199873  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Actor1Country</th>\n",
       "      <th>Actor1GeoCountry</th>\n",
       "      <th>Actor1Type</th>\n",
       "      <th>Actor2Country</th>\n",
       "      <th>Actor2GeoCountry</th>\n",
       "      <th>Actor2Type</th>\n",
       "      <th>ActionCountry</th>\n",
       "      <th>EventType</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>NumSources</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>AvgTone</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Impact_bin</th>\n",
       "      <th>pct_change_15min</th>\n",
       "      <th>pct_change_30min</th>\n",
       "      <th>pct_change_24h</th>\n",
       "      <th>AbsChange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-1.530752</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.605751</td>\n",
       "      <td>0.889228</td>\n",
       "      <td>2.004333</td>\n",
       "      <td>1.164239</td>\n",
       "      <td>0.375252</td>\n",
       "      <td>0.714246</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>-0.199873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-1.530752</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.731167</td>\n",
       "      <td>0.367070</td>\n",
       "      <td>0.597142</td>\n",
       "      <td>0.468568</td>\n",
       "      <td>-0.716820</td>\n",
       "      <td>0.425568</td>\n",
       "      <td>Slightly Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>-0.199873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-1.530752</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.563945</td>\n",
       "      <td>4.022178</td>\n",
       "      <td>1.300737</td>\n",
       "      <td>1.004049</td>\n",
       "      <td>0.960180</td>\n",
       "      <td>0.848379</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>-0.199873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-1.530752</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.523000</td>\n",
       "      <td>0.367070</td>\n",
       "      <td>-0.036094</td>\n",
       "      <td>-0.520616</td>\n",
       "      <td>0.334805</td>\n",
       "      <td>-0.355905</td>\n",
       "      <td>Slightly Negative</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>-0.199873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-1.530752</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.292209</td>\n",
       "      <td>1.933545</td>\n",
       "      <td>-0.247173</td>\n",
       "      <td>0.921836</td>\n",
       "      <td>-0.100779</td>\n",
       "      <td>0.329342</td>\n",
       "      <td>Slightly Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>-0.199873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:33:23.368160Z",
     "start_time": "2024-12-08T20:33:21.609445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = data.sample(1000000)\n",
    "sample.reset_index(drop=True, inplace=True)"
   ],
   "id": "335f8891bc9707ad",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:47:08.502046Z",
     "start_time": "2024-12-08T20:33:23.533576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.GELU(),  # GELU instead of ReLU/LeakyReLU\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.LayerNorm(in_features),\n",
    "        )\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gelu(x + self.block(x))\n",
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial feature extraction\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            ResidualBlock(32),\n",
    "            ResidualBlock(32),\n",
    "            ResidualBlock(32)\n",
    "        )\n",
    "        \n",
    "        # Price movement prediction\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LayerNorm(16),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight, gain=1e-2)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        return self.predictor(x)\n",
    "\n",
    "def train_model(X, y, batch_size=128, epochs=100):\n",
    "    \"\"\"Train with improved monitoring\"\"\"\n",
    "    \n",
    "    # Split data - use last 20% for validation\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    if hasattr(X_train, 'values'):\n",
    "        X_train = X_train.values\n",
    "        X_val = X_val.values\n",
    "    if hasattr(y_train, 'values'):\n",
    "        y_train = y_train.values\n",
    "        y_val = y_val.values\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_train),\n",
    "        torch.FloatTensor(y_train)\n",
    "    )\n",
    "    val_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_val),\n",
    "        torch.FloatTensor(y_val)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PricePredictor(input_dim=X.shape[1])\n",
    "    \n",
    "    # Custom loss combining MSE and directional accuracy\n",
    "    class DirectionalMSELoss(nn.Module):\n",
    "        def __init__(self, alpha=0.7):\n",
    "            super().__init__()\n",
    "            self.alpha = alpha\n",
    "            self.mse = nn.MSELoss()\n",
    "\n",
    "        def forward(self, pred, target):\n",
    "            mse_loss = self.mse(pred, target)\n",
    "            # Directional loss\n",
    "            direction_loss = torch.mean(\n",
    "                1 - torch.sign(pred) * torch.sign(target)\n",
    "            )\n",
    "            return self.alpha * mse_loss + (1 - self.alpha) * direction_loss\n",
    "\n",
    "    criterion = DirectionalMSELoss()\n",
    "    \n",
    "    # Optimizer with cosine annealing\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,  # Reset every 10 epochs\n",
    "        T_mult=2  # Double the reset interval after each reset\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_directions = []\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Calculate direction accuracy\n",
    "            pred_direction = torch.sign(outputs.detach())\n",
    "            true_direction = torch.sign(batch_y.reshape(-1, 1))\n",
    "            train_directions.append(\n",
    "                (pred_direction == true_direction).float().mean().item()\n",
    "            )\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_directions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                outputs = model(batch_X)\n",
    "                val_loss = criterion(outputs, batch_y.reshape(-1, 1))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                pred_direction = torch.sign(outputs)\n",
    "                true_direction = torch.sign(batch_y.reshape(-1, 1))\n",
    "                val_directions.append(\n",
    "                    (pred_direction == true_direction).float().mean().item()\n",
    "                )\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        train_dir_acc = np.mean(train_directions)\n",
    "        val_dir_acc = np.mean(val_directions)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        print(f'Train Loss: {train_loss:.6f}, Dir Acc: {train_dir_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.6f}, Dir Acc: {val_dir_acc:.4f}')\n",
    "        print(f'LR: {scheduler.get_last_lr()[0]:.6f}\\n')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "X, y, scaler = prep_data(sample)\n",
    "\n",
    "# Train model\n",
    "# model = train_model(X, y)"
   ],
   "id": "ff66e408a0b1e65c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "Train Loss: 0.520534, Dir Acc: 0.5013\n",
      "Val Loss: 0.512938, Dir Acc: 0.5028\n",
      "LR: 0.000976\n",
      "\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.520485, Dir Acc: 0.5013\n",
      "Val Loss: 0.512943, Dir Acc: 0.5028\n",
      "LR: 0.000905\n",
      "\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.519841, Dir Acc: 0.5024\n",
      "Val Loss: 0.518164, Dir Acc: 0.4941\n",
      "LR: 0.000794\n",
      "\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.520391, Dir Acc: 0.5015\n",
      "Val Loss: 0.512932, Dir Acc: 0.5028\n",
      "LR: 0.000655\n",
      "\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.519914, Dir Acc: 0.5023\n",
      "Val Loss: 0.518151, Dir Acc: 0.4941\n",
      "LR: 0.000500\n",
      "\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.519540, Dir Acc: 0.5029\n",
      "Val Loss: 0.518202, Dir Acc: 0.4941\n",
      "LR: 0.000345\n",
      "\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.519807, Dir Acc: 0.5024\n",
      "Val Loss: 0.512935, Dir Acc: 0.5028\n",
      "LR: 0.000206\n",
      "\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.519736, Dir Acc: 0.5026\n",
      "Val Loss: 0.514279, Dir Acc: 0.5005\n",
      "LR: 0.000095\n",
      "\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.519352, Dir Acc: 0.5032\n",
      "Val Loss: 0.514468, Dir Acc: 0.5002\n",
      "LR: 0.000024\n",
      "\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.519281, Dir Acc: 0.5033\n",
      "Val Loss: 0.513837, Dir Acc: 0.5013\n",
      "LR: 0.001000\n",
      "\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.520552, Dir Acc: 0.5012\n",
      "Val Loss: 0.512993, Dir Acc: 0.5028\n",
      "LR: 0.000994\n",
      "\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.520634, Dir Acc: 0.5011\n",
      "Val Loss: 0.512939, Dir Acc: 0.5028\n",
      "LR: 0.000976\n",
      "\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.520272, Dir Acc: 0.5017\n",
      "Val Loss: 0.512949, Dir Acc: 0.5028\n",
      "LR: 0.000946\n",
      "\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.520169, Dir Acc: 0.5019\n",
      "Val Loss: 0.512945, Dir Acc: 0.5028\n",
      "LR: 0.000905\n",
      "\n",
      "Early stopping triggered at epoch 14\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
