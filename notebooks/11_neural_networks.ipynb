{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:28.691155Z",
     "start_time": "2024-12-06T11:31:28.685598Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.140141Z",
     "start_time": "2024-12-06T11:31:28.704553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data = pd.read_parquet('../cache/encoded.parquet')"
   ],
   "id": "f03b740df0f7c595",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.159619Z",
     "start_time": "2024-12-06T11:31:31.155955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GDELT(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        if hasattr(features, 'values'):\n",
    "            features = features.values\n",
    "        if hasattr(target, 'values'):\n",
    "            target = target.values\n",
    "           \n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]"
   ],
   "id": "293439ff67b6a91a",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.176734Z",
     "start_time": "2024-12-06T11:31:31.174070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # simple neural network with 3 layers (linear)\n",
    "        self.network = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(input_dim, 128), # input layer to hidden layer 1 with 128 neurons\n",
    "            nn.BatchNorm1d(128), # batch normalization layer to normalize the output of the 1st layer before activation function is applied to it\n",
    "            nn.ReLU(), # activation function to introduce non-linearity to the model output from the 1st layer\n",
    "            nn.Dropout(0.3), # dropout layer to prevent overfitting by randomly setting 30% of the output from the 1st layer to 0\n",
    "        \n",
    "            # 2nd layer\n",
    "            nn.Linear(128, 64), # hidden layer 1 to hidden layer 2 with 64 neurons\n",
    "            nn.BatchNorm1d(64), # batch normalization layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.Dropout(0.3), # dropout layer\n",
    "        \n",
    "            # 3rd layer\n",
    "            nn.Linear(64, 32), # hidden layer 2 to hidden layer 3 with 32 neurons\n",
    "            nn.BatchNorm1d(32), # batch normalization layer\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.Dropout(0.3), # dropout layer\n",
    "        \n",
    "            # output layer\n",
    "            nn.Linear(32, 1) # hidden layer 3 to output layer with 1 neuron\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "id": "a79894d2e5735342",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.190664Z",
     "start_time": "2024-12-06T11:31:31.186565Z"
    }
   },
   "cell_type": "code",
   "source": "data.columns",
   "id": "514519bd36ec2724",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Timestamp', 'Actor1Country', 'Actor1GeoCountry', 'Actor1Type',\n",
       "       'Actor1TypeGeneral', 'Actor2Country', 'Actor2GeoCountry', 'Actor2Type',\n",
       "       'Actor2TypeGeneral', 'ActionCountry', 'EventType', 'GoldsteinScale',\n",
       "       'NumSources', 'NumArticles', 'AvgTone', 'Source', 'Magnitude', 'Impact',\n",
       "       'Impact_bin', 'pct_change_15min', 'pct_change_30min', 'pct_change_24h',\n",
       "       'QuadClass_VerbalCoop', 'QuadClass_MaterialCoop',\n",
       "       'QuadClass_VerbalConf', 'QuadClass_MaterialConf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.208040Z",
     "start_time": "2024-12-06T11:31:31.202819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prep_data(df, target='pct_change_30min'):\n",
    "    feature_cols = [\n",
    "        'Actor1Country', 'Actor1GeoCountry', 'Actor1Type', 'Actor1TypeGeneral',\n",
    "        'Actor2Country', 'Actor2GeoCountry', 'Actor2Type', 'Actor2TypeGeneral',\n",
    "        'ActionCountry', 'EventType', 'GoldsteinScale', \n",
    "        'QuadClass_VerbalCoop', 'QuadClass_MaterialCoop', 'QuadClass_VerbalConf', 'QuadClass_MaterialConf',\n",
    "        'NumSources', 'NumArticles', 'AvgTone',\n",
    "        'Magnitude', 'Impact'\n",
    "    ]\n",
    "    \n",
    "    booleans = ['QuadClass_VerbalCoop', 'QuadClass_MaterialCoop', 'QuadClass_VerbalConf', 'QuadClass_MaterialConf']\n",
    "    \n",
    "    for col in booleans:\n",
    "        df[col] = df[col].astype(int)\n",
    "        \n",
    "    x = df[feature_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    \n",
    "    return x_scaled, y, scaler"
   ],
   "id": "40984dcb08acc1bf",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.239869Z",
     "start_time": "2024-12-06T11:31:31.234292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(x, y, batch_size=256, epochs=50, learning_rate=0.001, patience=10):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    train_idx, test_idx = list(tscv.split(x))[-1] # use the last split as test set\n",
    "    \n",
    "    x_train, y_train = x[train_idx], y[train_idx]\n",
    "    x_val, y_val = x[test_idx], y[test_idx]\n",
    "    \n",
    "    train_dataset = GDELT(x_train, y_train)\n",
    "    val_dataset = GDELT(x_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = PricePredictor(x.shape[1])\n",
    "    \n",
    "    criterion = nn.MSELoss() # loss function (mean squared error)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for features, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, target.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, target in val_loader:\n",
    "                output = model(features)\n",
    "                loss = criterion(output, target.reshape(-1, 1))\n",
    "                val_loss += loss.item()\n",
    "                predictions.extend(output.numpy().flatten())\n",
    "                actuals.extend(target.numpy().flatten())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, accuracy: {np.mean(np.sign(predictions) == np.sign(actuals))}')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(f'Early stopping at epoch {epoch+1} with val loss: {val_loss:.4f}')\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_model.state_dict())\n",
    "    return model"
   ],
   "id": "efb9f0b31df5409f",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:31.259034Z",
     "start_time": "2024-12-06T11:31:31.249056Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "40c9b1e978879593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Timestamp  Actor1Country  Actor1GeoCountry  Actor1Type  \\\n",
       "0 2019-01-01  1546300800             21                21           4   \n",
       "1 2019-01-01  1546300800             16                 1          32   \n",
       "2 2019-01-01  1546300800             21                20           9   \n",
       "3 2019-01-01  1546300800             20                20          32   \n",
       "4 2019-01-01  1546300800             20                20           6   \n",
       "\n",
       "   Actor1TypeGeneral  Actor2Country  Actor2GeoCountry  Actor2Type  \\\n",
       "0                  4             21                21          32   \n",
       "1                  5             21                21          32   \n",
       "2                  2             21                20           9   \n",
       "3                  5             21                21          32   \n",
       "4                  0             21                21          32   \n",
       "\n",
       "   Actor2TypeGeneral  ...  Magnitude  Impact         Impact_bin  \\\n",
       "0                  5  ...       6.85    2.33           Positive   \n",
       "1                  5  ...       3.34    1.34  Slightly Positive   \n",
       "2                  2  ...       8.73    2.79           Positive   \n",
       "3                  5  ...       6.72   -1.34  Slightly Negative   \n",
       "4                  5  ...       5.32    1.01  Slightly Positive   \n",
       "\n",
       "   pct_change_15min  pct_change_30min  pct_change_24h QuadClass_VerbalCoop  \\\n",
       "0         -0.033061         -0.226363       -2.433464                 True   \n",
       "1         -0.033061         -0.226363       -2.433464                 True   \n",
       "2         -0.033061         -0.226363       -2.433464                 True   \n",
       "3         -0.033061         -0.226363       -2.433464                False   \n",
       "4         -0.033061         -0.226363       -2.433464                 True   \n",
       "\n",
       "   QuadClass_MaterialCoop  QuadClass_VerbalConf QuadClass_MaterialConf  \n",
       "0                   False                 False                  False  \n",
       "1                   False                 False                  False  \n",
       "2                   False                 False                  False  \n",
       "3                   False                  True                  False  \n",
       "4                   False                 False                  False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Actor1Country</th>\n",
       "      <th>Actor1GeoCountry</th>\n",
       "      <th>Actor1Type</th>\n",
       "      <th>Actor1TypeGeneral</th>\n",
       "      <th>Actor2Country</th>\n",
       "      <th>Actor2GeoCountry</th>\n",
       "      <th>Actor2Type</th>\n",
       "      <th>Actor2TypeGeneral</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Impact_bin</th>\n",
       "      <th>pct_change_15min</th>\n",
       "      <th>pct_change_30min</th>\n",
       "      <th>pct_change_24h</th>\n",
       "      <th>QuadClass_VerbalCoop</th>\n",
       "      <th>QuadClass_MaterialCoop</th>\n",
       "      <th>QuadClass_VerbalConf</th>\n",
       "      <th>QuadClass_MaterialConf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1546300800</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1546300800</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.34</td>\n",
       "      <td>Slightly Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1546300800</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1546300800</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>Slightly Negative</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1546300800</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.32</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Slightly Positive</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>-0.226363</td>\n",
       "      <td>-2.433464</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:31:32.147877Z",
     "start_time": "2024-12-06T11:31:31.294899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = data.sample(1000000)\n",
    "sample.reset_index(drop=True, inplace=True)"
   ],
   "id": "335f8891bc9707ad",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb88c9e42bc3fb22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T12:00:19.936027Z",
     "start_time": "2024-12-06T11:47:49.600093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.GELU(),  # GELU instead of ReLU/LeakyReLU\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.LayerNorm(in_features),\n",
    "        )\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gelu(x + self.block(x))\n",
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial feature extraction\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            ResidualBlock(32),\n",
    "            ResidualBlock(32),\n",
    "            ResidualBlock(32)\n",
    "        )\n",
    "        \n",
    "        # Price movement prediction\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LayerNorm(16),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight, gain=1e-2)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        return self.predictor(x)\n",
    "\n",
    "def train_model(X, y, batch_size=128, epochs=100):\n",
    "    \"\"\"Train with improved monitoring\"\"\"\n",
    "    \n",
    "    # Split data - use last 20% for validation\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    if hasattr(X_train, 'values'):\n",
    "        X_train = X_train.values\n",
    "        X_val = X_val.values\n",
    "    if hasattr(y_train, 'values'):\n",
    "        y_train = y_train.values\n",
    "        y_val = y_val.values\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_train),\n",
    "        torch.FloatTensor(y_train)\n",
    "    )\n",
    "    val_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_val),\n",
    "        torch.FloatTensor(y_val)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PricePredictor(input_dim=X.shape[1])\n",
    "    \n",
    "    # Custom loss combining MSE and directional accuracy\n",
    "    class DirectionalMSELoss(nn.Module):\n",
    "        def __init__(self, alpha=0.7):\n",
    "            super().__init__()\n",
    "            self.alpha = alpha\n",
    "            self.mse = nn.MSELoss()\n",
    "\n",
    "        def forward(self, pred, target):\n",
    "            mse_loss = self.mse(pred, target)\n",
    "            # Directional loss\n",
    "            direction_loss = torch.mean(\n",
    "                1 - torch.sign(pred) * torch.sign(target)\n",
    "            )\n",
    "            return self.alpha * mse_loss + (1 - self.alpha) * direction_loss\n",
    "\n",
    "    criterion = DirectionalMSELoss()\n",
    "    \n",
    "    # Optimizer with cosine annealing\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,  # Reset every 10 epochs\n",
    "        T_mult=2  # Double the reset interval after each reset\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_directions = []\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Calculate direction accuracy\n",
    "            pred_direction = torch.sign(outputs.detach())\n",
    "            true_direction = torch.sign(batch_y.reshape(-1, 1))\n",
    "            train_directions.append(\n",
    "                (pred_direction == true_direction).float().mean().item()\n",
    "            )\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_directions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                outputs = model(batch_X)\n",
    "                val_loss = criterion(outputs, batch_y.reshape(-1, 1))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                pred_direction = torch.sign(outputs)\n",
    "                true_direction = torch.sign(batch_y.reshape(-1, 1))\n",
    "                val_directions.append(\n",
    "                    (pred_direction == true_direction).float().mean().item()\n",
    "                )\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        train_dir_acc = np.mean(train_directions)\n",
    "        val_dir_acc = np.mean(val_directions)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        print(f'Train Loss: {train_loss:.6f}, Dir Acc: {train_dir_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.6f}, Dir Acc: {val_dir_acc:.4f}')\n",
    "        print(f'LR: {scheduler.get_last_lr()[0]:.6f}\\n')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "X, y, scaler = prep_data(sample)\n",
    "\n",
    "# Train model\n",
    "model = train_model(X, y)"
   ],
   "id": "8b074dc6833fe4e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "Train Loss: 0.518056, Dir Acc: 0.5009\n",
      "Val Loss: 0.514117, Dir Acc: 0.5068\n",
      "LR: 0.000976\n",
      "\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.517768, Dir Acc: 0.5014\n",
      "Val Loss: 0.514119, Dir Acc: 0.5068\n",
      "LR: 0.000905\n",
      "\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.518486, Dir Acc: 0.5002\n",
      "Val Loss: 0.514118, Dir Acc: 0.5068\n",
      "LR: 0.000794\n",
      "\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.518105, Dir Acc: 0.5008\n",
      "Val Loss: 0.524262, Dir Acc: 0.4900\n",
      "LR: 0.000655\n",
      "\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.517394, Dir Acc: 0.5020\n",
      "Val Loss: 0.514119, Dir Acc: 0.5068\n",
      "LR: 0.000500\n",
      "\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.517985, Dir Acc: 0.5010\n",
      "Val Loss: 0.514121, Dir Acc: 0.5068\n",
      "LR: 0.000345\n",
      "\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.517153, Dir Acc: 0.5024\n",
      "Val Loss: 0.514129, Dir Acc: 0.5068\n",
      "LR: 0.000206\n",
      "\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.517014, Dir Acc: 0.5026\n",
      "Val Loss: 0.514126, Dir Acc: 0.5068\n",
      "LR: 0.000095\n",
      "\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.516642, Dir Acc: 0.5032\n",
      "Val Loss: 0.514115, Dir Acc: 0.5068\n",
      "LR: 0.000024\n",
      "\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.516560, Dir Acc: 0.5033\n",
      "Val Loss: 0.514120, Dir Acc: 0.5068\n",
      "LR: 0.001000\n",
      "\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.518622, Dir Acc: 0.4999\n",
      "Val Loss: 0.514141, Dir Acc: 0.5068\n",
      "LR: 0.000994\n",
      "\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.518090, Dir Acc: 0.5008\n",
      "Val Loss: 0.514117, Dir Acc: 0.5068\n",
      "LR: 0.000976\n",
      "\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.518353, Dir Acc: 0.5004\n",
      "Val Loss: 0.524253, Dir Acc: 0.4900\n",
      "LR: 0.000946\n",
      "\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.518393, Dir Acc: 0.5003\n",
      "Val Loss: 0.514130, Dir Acc: 0.5068\n",
      "LR: 0.000905\n",
      "\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.517858, Dir Acc: 0.5012\n",
      "Val Loss: 0.524282, Dir Acc: 0.4900\n",
      "LR: 0.000854\n",
      "\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.518179, Dir Acc: 0.5007\n",
      "Val Loss: 0.522923, Dir Acc: 0.4922\n",
      "LR: 0.000794\n",
      "\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.518018, Dir Acc: 0.5009\n",
      "Val Loss: 0.519105, Dir Acc: 0.4986\n",
      "LR: 0.000727\n",
      "\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.517687, Dir Acc: 0.5015\n",
      "Val Loss: 0.524401, Dir Acc: 0.4900\n",
      "LR: 0.000655\n",
      "\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.517828, Dir Acc: 0.5013\n",
      "Val Loss: 0.513941, Dir Acc: 0.5071\n",
      "LR: 0.000578\n",
      "\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.517428, Dir Acc: 0.5019\n",
      "Val Loss: 0.516414, Dir Acc: 0.5030\n",
      "LR: 0.000500\n",
      "\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.517890, Dir Acc: 0.5011\n",
      "Val Loss: 0.521236, Dir Acc: 0.4950\n",
      "LR: 0.000422\n",
      "\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.517512, Dir Acc: 0.5018\n",
      "Val Loss: 0.514182, Dir Acc: 0.5067\n",
      "LR: 0.000345\n",
      "\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.517007, Dir Acc: 0.5026\n",
      "Val Loss: 0.515105, Dir Acc: 0.5052\n",
      "LR: 0.000273\n",
      "\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.517278, Dir Acc: 0.5021\n",
      "Val Loss: 0.513953, Dir Acc: 0.5071\n",
      "LR: 0.000206\n",
      "\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.516957, Dir Acc: 0.5027\n",
      "Val Loss: 0.514080, Dir Acc: 0.5069\n",
      "LR: 0.000146\n",
      "\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.516739, Dir Acc: 0.5030\n",
      "Val Loss: 0.515034, Dir Acc: 0.5053\n",
      "LR: 0.000095\n",
      "\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.516694, Dir Acc: 0.5031\n",
      "Val Loss: 0.515184, Dir Acc: 0.5051\n",
      "LR: 0.000054\n",
      "\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.516688, Dir Acc: 0.5031\n",
      "Val Loss: 0.515134, Dir Acc: 0.5052\n",
      "LR: 0.000024\n",
      "\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.516553, Dir Acc: 0.5033\n",
      "Val Loss: 0.514487, Dir Acc: 0.5062\n",
      "LR: 0.000006\n",
      "\n",
      "Early stopping triggered at epoch 29\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:35:56.425418Z",
     "start_time": "2024-12-06T11:31:32.169041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y, scaler = prep_data(sample)\n",
    "model = train_model(x, y, batch_size=256, epochs=100, learning_rate=0.001, patience=10)"
   ],
   "id": "d106b4a7f8f5f245",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, train loss: 0.3167, val loss: 0.3156, accuracy: 0.5052080208320834\n",
      "Epoch 2/100, train loss: 0.3133, val loss: 0.3156, accuracy: 0.50437401749607\n",
      "Epoch 3/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5062820251281005\n",
      "Epoch 4/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5065880263521054\n",
      "Epoch 5/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5065880263521054\n",
      "Epoch 6/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5064500258001032\n",
      "Epoch 7/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5064920259681038\n",
      "Epoch 8/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5067200268801075\n",
      "Epoch 9/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5068340273361094\n",
      "Epoch 10/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5069660278641115\n",
      "Epoch 11/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5069840279361117\n",
      "Epoch 12/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5069780279121117\n",
      "Epoch 13/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5064680258721035\n",
      "Epoch 14/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5062940251761007\n",
      "Epoch 15/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5069780279121117\n",
      "Epoch 16/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5067620270481082\n",
      "Epoch 17/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5063600254401017\n",
      "Epoch 18/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5063420253681015\n",
      "Epoch 19/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5059700238800955\n",
      "Epoch 20/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5063900255601023\n",
      "Epoch 21/100, train loss: 0.3132, val loss: 0.3156, accuracy: 0.5070440281761127\n",
      "Early stopping at epoch 21 with val loss: 0.3156\n"
     ]
    }
   ],
   "execution_count": 128
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
